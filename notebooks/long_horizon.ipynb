{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08f250e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent directory: /u/weim/lob\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import os\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "print(f\"Parent directory: {parent_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff36b006",
   "metadata": {},
   "outputs": [],
   "source": [
    "lots_list = [20,60]\n",
    "n_samples = 10000\n",
    "train_iter = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49d3a4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from /u/weim/lob/rewards/noise_20_episodes_10000_eval_seed_100_sl_agent.npz\n",
      "loading from /u/weim/lob/rewards/noise_20_episodes_10000_eval_seed_100_linear_sl_agent.npz\n",
      "loading from /u/weim/lob/rewards/noise_20_seed_0_eval_seed_100_eval_episodes_10000_num_iterations_400_bsize_12800_log_normal.npz\n",
      "loading from /u/weim/lob/rewards/noise_20_seed_0_eval_seed_100_eval_episodes_10000_num_iterations_400_bsize_12800_dirichlet.npz\n",
      "loading from /u/weim/lob/rewards/noise_60_episodes_10000_eval_seed_100_sl_agent.npz\n",
      "loading from /u/weim/lob/rewards/noise_60_episodes_10000_eval_seed_100_linear_sl_agent.npz\n",
      "loading from /u/weim/lob/rewards/noise_60_seed_0_eval_seed_100_eval_episodes_10000_num_iterations_400_bsize_12800_log_normal.npz\n",
      "loading from /u/weim/lob/rewards/noise_60_seed_0_eval_seed_100_eval_episodes_10000_num_iterations_400_bsize_12800_dirichlet.npz\n",
      "loading from /u/weim/lob/rewards/flow_20_episodes_10000_eval_seed_100_sl_agent.npz\n",
      "loading from /u/weim/lob/rewards/flow_20_episodes_10000_eval_seed_100_linear_sl_agent.npz\n",
      "loading from /u/weim/lob/rewards/flow_20_seed_0_eval_seed_100_eval_episodes_10000_num_iterations_400_bsize_12800_log_normal.npz\n",
      "loading from /u/weim/lob/rewards/flow_20_seed_0_eval_seed_100_eval_episodes_10000_num_iterations_400_bsize_12800_dirichlet.npz\n",
      "loading from /u/weim/lob/rewards/flow_60_episodes_10000_eval_seed_100_sl_agent.npz\n",
      "loading from /u/weim/lob/rewards/flow_60_episodes_10000_eval_seed_100_linear_sl_agent.npz\n",
      "loading from /u/weim/lob/rewards/flow_60_seed_0_eval_seed_100_eval_episodes_10000_num_iterations_400_bsize_12800_log_normal.npz\n",
      "loading from /u/weim/lob/rewards/flow_60_seed_0_eval_seed_100_eval_episodes_10000_num_iterations_400_bsize_12800_dirichlet.npz\n",
      "loading from /u/weim/lob/rewards/strategic_20_episodes_10000_eval_seed_100_sl_agent.npz\n",
      "loading from /u/weim/lob/rewards/strategic_20_episodes_10000_eval_seed_100_linear_sl_agent.npz\n",
      "loading from /u/weim/lob/rewards/strategic_20_seed_0_eval_seed_100_eval_episodes_10000_num_iterations_400_bsize_12800_log_normal.npz\n",
      "loading from /u/weim/lob/rewards/strategic_20_seed_0_eval_seed_100_eval_episodes_10000_num_iterations_400_bsize_12800_dirichlet.npz\n",
      "loading from /u/weim/lob/rewards/strategic_60_episodes_10000_eval_seed_100_sl_agent.npz\n",
      "loading from /u/weim/lob/rewards/strategic_60_episodes_10000_eval_seed_100_linear_sl_agent.npz\n",
      "loading from /u/weim/lob/rewards/strategic_60_seed_0_eval_seed_100_eval_episodes_10000_num_iterations_400_bsize_12800_log_normal.npz\n",
      "loading from /u/weim/lob/rewards/strategic_60_seed_0_eval_seed_100_eval_episodes_10000_num_iterations_400_bsize_12800_dirichlet.npz\n"
     ]
    }
   ],
   "source": [
    "# Should update this to include: Dirichlet, Normal+Softmax \n",
    "# Note: need more training iterations like 400 (or 500 iterations)\n",
    "# For 200 iterations, in the noise setting, the rl agent is not better than the noise agent \n",
    "# note dirichlet agents also seeems to work well \n",
    "lots_list = [20,60]\n",
    "n_samples = 10000\n",
    "train_iter = 400\n",
    "tag = 'GAE'  # could be empty string ''\n",
    "tag = None\n",
    "tage = 'long_horizon'\n",
    "batch_size = 12800\n",
    "\n",
    "\n",
    "folder_path = f\"{parent_dir}/rewards\"\n",
    "data = {}\n",
    "# agent_list = ['sl_agent', 'linear_sl_agent', 'log_normal', 'dirichlet']\n",
    "# agent_list = ['sl_agent', 'linear_sl_agent', 'log_normal', 'dirichlet']\n",
    "agent_list = ['sl_agent', 'linear_sl_agent', 'log_normal', 'dirichlet']\n",
    "for env in ['noise', 'flow', 'strategic']:\n",
    "    data[env] = {}\n",
    "    for lots in lots_list:\n",
    "        data[env][lots] = {}\n",
    "        for agent in agent_list:            \n",
    "            try: \n",
    "                if agent in ['log_normal', 'dirichlet']:               \n",
    "                    # small batch size \n",
    "                    # name =  f'{folder_path}/{env}_{lots}_seed_0_eval_seed_100_eval_episodes_10000_num_iterations_{train_iter}_bsize_3200_{agent}_GAE.npz'\n",
    "                    # medium batch size\n",
    "                    # name =  f'/u/weim/lob/rewards/{env}_{lots}_seed_0_eval_seed_100_eval_episodes_10000_num_iterations_400_bsize_6400_{agent}.npz'\n",
    "                    if tag is not None:\n",
    "                        name =  f'{folder_path}/{env}_{lots}_seed_0_eval_seed_100_eval_episodes_10000_num_iterations_{train_iter}_bsize_{batch_size}_{agent}_{tag}.npz'\n",
    "                    else:\n",
    "                        name =  f'{folder_path}/{env}_{lots}_seed_0_eval_seed_100_eval_episodes_10000_num_iterations_{train_iter}_bsize_{batch_size}_{agent}.npz'\n",
    "                else:\n",
    "                    # might need to updating the naming here\n",
    "                    name = f'{folder_path}/{env}_{lots}_episodes_{10000}_eval_seed_100_{agent}.npz'\n",
    "                print(f'loading from {name}')\n",
    "                data[env][lots][agent] = np.load(name)['rewards']\n",
    "            except:\n",
    "                print(f\"path doesnt exist: {name}\")\n",
    "                data[env][lots][agent] = 'no data aviailable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0372a83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sl_agent\n",
      "linear_sl_agent\n",
      "log_normal\n",
      "dirichlet\n",
      "sl_agent\n",
      "linear_sl_agent\n",
      "log_normal\n",
      "dirichlet\n",
      "sl_agent\n",
      "linear_sl_agent\n",
      "log_normal\n",
      "dirichlet\n",
      "              E[SL]  Std[SL]  E[TWAP]  Std[TWAP]  E[LN]  Std[LN]  E[DR]  \\\n",
      "noise_20       0.52     1.19    -0.06       0.94   0.64     0.88   0.46   \n",
      "noise_60      -1.09     1.34    -1.40       0.98  -0.81     0.93  -0.79   \n",
      "flow_20        0.10     1.43     0.48       0.68   0.79     0.67   0.72   \n",
      "flow_60       -3.36     0.99    -0.96       0.95  -0.24     0.66  -0.34   \n",
      "strategic_20  -1.64     2.95    -0.36       3.03   1.11     2.23   1.01   \n",
      "strategic_60  -2.51     3.67    -1.45       3.46   0.11     2.42   0.03   \n",
      "\n",
      "              Std[DR]  \n",
      "noise_20         0.91  \n",
      "noise_60         0.98  \n",
      "flow_20          0.67  \n",
      "flow_60          0.66  \n",
      "strategic_20     2.12  \n",
      "strategic_60     1.99  \n",
      "                         Market \\#Lots  E[SL] Std[SL] E[TWAP] Std[TWAP]  \\\n",
      "noise_20                  Noise     20   0.52    1.19   -0.06      0.94   \n",
      "noise_60                            60  -1.09    1.34    -1.4      0.98   \n",
      "flow_20       Noise \\& Tactical     20    0.1    1.43    0.48      0.68   \n",
      "flow_60                             60  -3.36    0.99   -0.96      0.95   \n",
      "strategic_20  Noise \\& Tactical     20  -1.64    2.95   -0.36      3.03   \n",
      "strategic_60       \\& Strategic     60  -2.51    3.67   -1.45      3.46   \n",
      "\n",
      "                       E[LN]        Std[LN]           E[DR]        Std[DR]  \n",
      "noise_20       \\textbf{0.64}  \\textbf{0.88}            0.46           0.91  \n",
      "noise_60               -0.81  \\textbf{0.93}  \\textbf{-0.79}           0.98  \n",
      "flow_20        \\textbf{0.79}  \\textbf{0.67}            0.72           0.67  \n",
      "flow_60       \\textbf{-0.24}  \\textbf{0.66}           -0.34           0.66  \n",
      "strategic_20   \\textbf{1.11}           2.23            1.01  \\textbf{2.12}  \n",
      "strategic_60   \\textbf{0.11}           2.42            0.03  \\textbf{1.99}  \n"
     ]
    }
   ],
   "source": [
    "# medium batch results are not as good as large batch results \n",
    "# tag = 'small_batch'\n",
    "# tag = 'small_batch_GAE'\n",
    "# tag = 'medium_batch'\n",
    "\n",
    "folder_path = f\"{parent_dir}/latex_tables\"\n",
    "list_of_dfs = []\n",
    "# n_lots = [20, 60]\n",
    "# print(filler)\n",
    "for env in ['noise', 'flow', 'strategic']:\n",
    "    data_for_df = {}\n",
    "    name_dict = {'sl_agent': 'SL', 'linear_sl_agent': 'TWAP', 'dirichlet': 'DR', 'log_normal': 'LN', 'log_normal_learn_std': 'LNVAR'}\n",
    "    # agent_names = ['sl_agent', 'linear_sl_agent', 'dirichlet', 'log_normal']\n",
    "    agent_names = ['sl_agent', 'linear_sl_agent', 'log_normal', 'dirichlet']\n",
    "    for agent in agent_names:\n",
    "        print(agent)\n",
    "        name = name_dict[agent]\n",
    "        data_for_df[f'E[{name}]'] = []\n",
    "        data_for_df[f'Std[{name}]'] = []\n",
    "        for lots in lots_list:\n",
    "            try:\n",
    "                data_for_df[f'Std[{name}]'] += [np.std(data[env][lots][agent])]\n",
    "                data_for_df[f'E[{name}]'] += [np.mean(data[env][lots][agent])]                \n",
    "            except:\n",
    "                print(f\"no data available for {env}, {lots}, {agent}\")\n",
    "                data_for_df[f'Std[{name}]'] += [np.nan]\n",
    "                data_for_df[f'E[{name}]'] += [np.nan]\n",
    "    df = pd.DataFrame.from_dict(data_for_df).round(2)    \n",
    "    df.index.name = 'Lots'\n",
    "    index_name = [f'{env}_{l}' for l in lots_list]\n",
    "    df.index = index_name\n",
    "    df = df.round(2)\n",
    "    list_of_dfs.append(df)\n",
    "\n",
    "complete_df = pd.concat(list_of_dfs, axis=0)\n",
    "print(complete_df)\n",
    "\n",
    "\n",
    "highest_exp = []\n",
    "lowest_std = []\n",
    "for idx in complete_df.index:\n",
    "    # expected_values = complete_df.loc[idx, ['E[SL]', 'E[TWAP]', 'E[DR]', 'E[LN]']]\n",
    "    expected_values = complete_df.loc[idx, ['E[SL]', 'E[TWAP]', 'E[LN]', 'E[DR]']]\n",
    "    max_idx = expected_values.idxmax()\n",
    "    highest_exp.append((idx, max_idx))\n",
    "    # std_values = complete_df.loc[idx, ['Std[SL]', 'Std[TWAP]', 'Std[DR]', 'Std[LN]']]\n",
    "    std_values = complete_df.loc[idx, ['Std[SL]', 'Std[TWAP]', 'Std[LN]', 'Std[DR]']]\n",
    "    min_idx = std_values.idxmin()\n",
    "    lowest_std.append((idx, min_idx))\n",
    "\n",
    "complete_df = complete_df.astype(str)\n",
    "for idx, max_idx in highest_exp:\n",
    "    complete_df.loc[idx, max_idx] = fr\"\\textbf{{{complete_df.loc[idx, max_idx]}}}\"\n",
    "\n",
    "for idx, min_idx in lowest_std:\n",
    "    complete_df.loc[idx, min_idx] = fr\"\\textbf{{{complete_df.loc[idx, min_idx]}}}\"\n",
    "\n",
    "complete_df = complete_df.drop(['noise', 'flow', 'strategic'], errors='ignore')\n",
    "complete_df.insert(0, r'\\#Lots', complete_df.index.astype(str))\n",
    "complete_df.iloc[:,0] = [20,60]*3\n",
    "\n",
    "complete_df.insert(0, r'Market', complete_df.index.astype(str))\n",
    "complete_df.iloc[:,0] = ['Noise', '', 'Noise \\& Tactical', '', 'Noise \\& Tactical', '\\& Strategic']\n",
    "\n",
    "rename_dict = {'E[SL]': r'$\\mathbb{E}[\\text{SL}]$', 'Std[SL]': r'$\\sigma[\\text{SL}]$', \n",
    "               'E[TWAP]': r'$\\mathbb{E}[\\text{TWAP}]$', 'Std[TWAP]': r'$\\sigma[\\text{TWAP}]$', \n",
    "               'E[LN]': r'$\\mathbb{E}[\\text{LN}]$', 'Std[LN]': r'$\\sigma[\\text{LN}]$', \n",
    "               'E[DR]': r'$\\mathbb{E}[\\text{DR}]$', 'Std[DR]': r'$\\sigma[\\text{DR}]$',\n",
    "            #    'E[DR]': r'$\\mathbb{E}[\\text{LNVAR}]$', 'Std[LNVAR]': r'$\\sigma[\\text{LNVAR}]$'\n",
    "               }\n",
    "print(complete_df)\n",
    "complete_df = complete_df.rename(columns=rename_dict)\n",
    "complete_df = complete_df.where(pd.notnull(complete_df), '')\n",
    "\n",
    "latex_table = complete_df.to_latex(float_format=\"%.2f\", index=False, column_format='l'+'c'*9, escape=False)\n",
    "saving_path = f\"{folder_path}/results_table_latest_with_dirichlet_{tag}.tex\" if tag is not None else f\"{folder_path}/results_table_latest_with_dirichlet.tex\"\n",
    "saving_path = f\"{folder_path}/results_table_log_normal_long_horizon.tex\" \n",
    "tag = '' if tag is None else tag\n",
    "with open(saving_path, \"w\") as f:\n",
    "    content = (\n",
    "        r\"\\begin{table}[htpb]\"+\n",
    "        r\"\\label{table:\" + tag +\"}\"+\n",
    "        r\"\\begin{center}\"+\n",
    "        r\"    \\begin{scriptsize}\"+\n",
    "        r\"        \\begin{sc}\"\n",
    "        + latex_table +\n",
    "        r\"        \\end{sc}\"+\n",
    "        r\"    \\end{scriptsize}\"+\n",
    "        r\"\\end{center}\"+\n",
    "        r\"\\end{table}\"        \n",
    "    )\n",
    "    f.write(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
